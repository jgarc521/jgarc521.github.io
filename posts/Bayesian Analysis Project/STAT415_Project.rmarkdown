---
title: "STAT 415 Project"
format: html
editor: visual
---

```{r}
library(dplyr)
library(tidyverse)
library(ggplot2)
library(brms)
library(tidybayes)
library(kableExtra)

bayes_col = c("#56B4E9", "#E69F00", "#009E73", "#CC79A7", "#CC79A7")
names(bayes_col) = c("prior", "likelihood", "posterior", "prior_predict", "posterior_predict")

bayes_lty = c("dashed", "dotted", "solid")
names(bayes_lty) = c("prior", "likelihood", "posterior")
```



## Research Question and Context

Our research question is how does flight departure delay affect customer satisfaction with a flight? The departure delay time will be measured in minutes and we will determine if it influences whether a customer is satisfied or not satisfied with a flight.

## Data



```{r}
airline <- read.csv("/Users/josegarcia/Downloads/airline_data.csv")
airline <- airline %>%
  select(Departure.Delay.in.Minutes, satisfaction) %>%
  rename(dep_delay = Departure.Delay.in.Minutes)
airline <- airline[1:1000,]
airline$satisfaction <- ifelse(airline$satisfaction == "satisfied", 1, 0)
```



We collected data from Kaggle which is a data science platform and online community for data scientists and machine learning practitioners under Google LLC. https://www.kaggle.com/datasets/raminhuseyn/airline-customer-satisfaction

The dataset provides a look into customer satisfaction, either satisfied or not satisfied. The data was collected from an undisclosed airline company. There are 129,880 samples within the dataset, but we will be exploring the first 1,000 samples in the dataset. If the dataset is too big it will have too much influence on the posterior distribution, and our prior will not have any influence.

## Proposed Bayesian Model

Based on the data, we propose a Bayesian analog of a logistic regression which is modeled as:

log($\pi$ / 1 - $\pi$i) = $\beta_0$ + $\beta_1x_j$ .

## Prior Distribution of the Parameters

For our parameters, we chose the following priors:

-   $\beta_0$ (Intercept) \~ N(0, 10)

    -   Prior to seeing the data, we believe the baseline log-odds of satisfaction (when departure delay is zero) could reasonably vary but are centered around zero, reflecting no strong initial bias toward satisfaction or dissatisfaction.

-   $\beta_1$ (Coefficient for Departure Delay) \~ N(0, 2)

    -   We expect that each minute of delay could slightly increase or decrease the probability of satisfaction, but probably not dramatically on a minute-by-minute basis. Therefore, a normal distribution with a smaller standard deviation could make sense, reflecting our belief that substantial changes in odds are unlikely with small changes in delay.



```{r}
n_rep = 1000
x = runif(n_rep, 0, 1600)  

# Simulate parameters from the prior distribution
beta0 <- rnorm(n_rep, 0, 10)  
beta1 <- rnorm(n_rep, 0, 2)      

# Simulate values of satisfaction 
p = exp(beta0 + beta1 * x) / (1 + exp(beta0 + beta1 * x))
y_pred = rbinom(n_rep, 1, p)

# Create a dataframe 
sim_data <- data.frame(dep_delay = x, y_pred = y_pred)

# Plot 
ggplot(sim_data, aes(x = dep_delay, y = y_pred)) + 
  geom_jitter(width = 0.1, height = 0.05, alpha = 0.5) +
  labs(x = "Departure Delay (minutes)", y = "Predicted Satisfaction",
       title = "Prior Predictive Distribution of Satisfaction")
```



After some prior predictive tuning, the resulting plot showcases a lower predicted satisfaction for higher values of departure delay, as seen in the greater density of points at 0 (not satisfied).

## BRMS Model



```{r}
fit <- brm(data = airline,
           satisfaction ~ dep_delay,
           family = bernoulli(),
           refresh = 0)
```



## Posterior Inference



```{r}
prior_summary(fit)
summary(fit)
plot(fit)
pairs(fit)
```

```{r}
ci <- posterior_summary(fit, probs = c(0.025, 0.975))
print(ci)
```



## Posterior Predictive Distribution



```{r}
y_predict = posterior_predict(fit)
y_predict = data.frame(y_sim = y_predict[, 1])

# Create the labels
y_predict$y_sim <- factor(y_predict$y_sim, levels = c(0, 1), labels = c("Not Satisfied (0)", "Satisfied (1)"))

# Create summary for percentages
summary <- y_predict |>
  group_by(y_sim) |>
  summarise(Count = n()) |>
  mutate(Percentage = paste0(round(100 * Count / sum(Count), 1), "%"))

# Bar plot
ggplot(summary, aes(x = y_sim, y = Count, fill = y_sim)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = Percentage), vjust = -0.3, size = 5) +
  labs(title = "Posterior Predictions for a Single X",
       x = "Prediction of Satisfaction", 
       y = "Count") +
  theme_minimal()
```



The bar plot showing the posterior predictions from a logistic regression model indicates a strong skew towards predicting satisfaction, with about 91.7% of outcomes favoring satisfaction and only 8.3% not. This distribution suggests possible overconfidence or overfitting, where the model might be too finely tuned to the data, potentially failing to capture less frequent outcomes of dissatisfaction accurately.

## Sensitivity Analysis



```{r}
fit_prior <- brm(data = airline,
           satisfaction ~ dep_delay,
           family = bernoulli(),
           prior = c(prior(normal(0, 10), class = Intercept),
                prior(normal(0, 2), class = b)),
           refresh = 0)
```

```{r}
summary(fit_prior)
plot(fit_prior)
pairs(fit_prior)
pairs(fit_prior)
```

```{r}
ci <- posterior_summary(fit_prior, probs = c(0.025, 0.975))
print(ci)
```



After setting our own priors for our model, we got results that we the same. The \$\\beta_0\$ value was the exact same of 2.27. The \$\\beta_1\$ values or the slope, were the exact same at -0.01. The 95% credible interval for the intercept is approximately \[2.06, 2.48\], indicating that we are 95% confident that the true intercept lies within this range. This was pretty much the same as the 95% confidence interval for brm's priors that was \[2.06, 2.49\]. The 95% credible interval for \`dep_delay\` is approximately \[-0.016, -0.006\], there is a 95% probability that the true value from dep_delay is within the interval. This is sightly different from the 95% credible interval for brm's priors that was \[-0.010, 0.003\]. This is probably because brm chose a flat prior for the slope, but we picked one that included some prior knowledge on the slope. Overall, the prior had very little influence on the posterior distribution. So the model is not very sensitivity to the prior.

## Frequentist Analysis



```{r}
# Fit the logistic regression model
fit_glm <- glm(satisfaction ~ dep_delay, family = binomial(link = "logit"), data = airline)

# Summarize the model
summary(fit_glm)
```

```{r}
# Calculate confidence intervals
confint(fit_glm)

# Predict the probabilities of customer satisfication
predicted_probs <- predict(fit_glm, type = "response")
```



After doing a frequentist analysis of our logistical regression model, we got similar results. The $\beta_0$ values were very similar, it was 2.27 for the Bayes Analysis and 2.26 for the frequentist analysis. The $\beta_1$ values or the slope, were the exact same at -0.01. The confidence interval for the intercept is \[2.053, 2.488\]. This means we are 95% of the sample intervals will capture the true intercept. The confidence interval for \`dep_delay\` is \[-0.0152, -0.005\], suggesting a negative association with the probability of a customer association. They produce similar intervals that are interpreted differently.

## Conclusions

Looking at the posterior estimates for $\beta_0$ and $\beta_1$, the estimate for $\beta_0$ is 2.27 and $\beta_1$ is -0.01. The 95% credible interval for the intercept is approximately \[2.06, 2.49\], indicating that we are 95% confident that the true intercept lies within this range. The 95% credible interval for \$\\beta_1\$ is approximately \[-0.010, 0.003\], there is a 95% probability that the true value from dep_delay is within the interval. This means that there is a slight negative association with the departure delay and the probability of a customer being satisfied. $\beta_1$ is the log-odds of a passenger being satisfied or not with each additional minute of delay. Our research question was how does flight departure delay affect customer satisfaction with a flight? We found that the negative association tells us that as departure delay increases, the log-odds of a passenger being satisfied is going to decrease.


