[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jose Garcia",
    "section": "",
    "text": "Welcome to my site!\nMy name is Jose Garcia, a 5th year student studying Statistics at California Polytechnic State University, San Luis Obispo. I am from San Jose, CA and some of my hobbies include: hiking, playing and watching sports, and coding.\nIf you have any questions, do not hesitate to reach out. Thank you!\nClick the links for more info about me, or, check out some of my projects above."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "More to come soon!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Advanced Visualizations\n\n\n\n\n\nVisualizations from Lab 2\n\n\n\n\n\nApr 14, 2025\n\n\nJose Garcia\n\n\n\n\n\n\n\nStatic Dashboard\n\n\n\n\n\nDashboard made for Lab 3\n\n\n\n\n\nApr 21, 2025\n\n\nJose Garcia\n\n\n\n\n\n\n\nDynamic Dashboard\n\n\n\n\n\nDashboard from Lab 3 updated with interactivity for Lab 4\n\n\n\n\n\nApr 28, 2025\n\n\nJose Garcia\n\n\n\n\n\n\n\nWriting Efficient Functions\n\n\n\n\n\nFunctions from Lab 6\n\n\n\n\n\nMay 12, 2025\n\n\nJose Garcia\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/third-post/index.html",
    "href": "posts/third-post/index.html",
    "title": "Lab 2",
    "section": "",
    "text": "Create a Quarto file for ALL Lab 2 (no separate files for Parts 1 and 2).\n\nMake sure your final file is carefully formatted, so that each analysis is clear and concise.\nBe sure your knitted .html file shows all your source code, including any function definitions.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(wesanderson)\nlibrary(leaflet)\nlibrary(rnaturalearth)\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout"
  },
  {
    "objectID": "posts/third-post/index.html#dissecting-a-bad-visualization",
    "href": "posts/third-post/index.html#dissecting-a-bad-visualization",
    "title": "Lab 2",
    "section": "Dissecting a Bad Visualization",
    "text": "Dissecting a Bad Visualization\nBelow is an example of a less-than-ideal visualization from the collection linked above. It comes to us from data provided for the Wellcome Global Monitor 2018 report by the Gallup World Poll:\n\nWhile there are certainly issues with this image, do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\nThe graph is showing us the percent of people who believe vaccines are safe by country and global region. The authors could be trying to convey regional differences in vaccine trust, outliers, and a central theme that higher-income countries (such as the US) do not always have high trust in vaccines.\n\nList the variables that appear to be displayed in this visualization. Hint: Variables refer to columns in the data.\n\nCountry, region, % of trust, median vaccine trust by region.\n\nNow that you’re versed in the grammar of graphics (e.g., ggplot), list the aesthetics used and which variables are mapped to each.\n\n\nx = % who believe in vaccines\ny = country\ncolor = region\n\n\nWhat type of graph would you call this? Meaning, what geom would you use to produce this plot?\n\nBecause each individual observation is a point, I would call this a geom_point() plot.\n\nProvide at least four problems or changes that would improve this graph. Please format your changes as bullet points!\n\n\nDifferent colors, make them more fun!\nUse faceting to remove stacking\nIncrease font size\nRemove legend (according to Will Chase)"
  },
  {
    "objectID": "posts/third-post/index.html#improving-the-bad-visualization",
    "href": "posts/third-post/index.html#improving-the-bad-visualization",
    "title": "Lab 2",
    "section": "Improving the Bad Visualization",
    "text": "Improving the Bad Visualization\nThe data for the Wellcome Global Monitor 2018 report can be downloaded at the following site: https://wellcome.ac.uk/reports/wellcome-global-monitor/2018\n\nThere are two worksheets in the downloaded dataset file. You may need to read them in separately, but you may also just use one if it suffices.\n\ndict &lt;- readxl::read_excel(\"/Users/josegarcia/Desktop/STAT_541/wgm2018.xlsx\", sheet = \"Data dictionary\")\n\ndata &lt;- readxl::read_excel(\"/Users/josegarcia/Desktop/STAT_541/wgm2018.xlsx\", sheet = \"Full dataset\") |&gt;\n  rename(code = WP5)\n\n\n# country codes\ncountry_codes_list &lt;- dict$`Variable Type & Codes*`[1] |&gt;\n  str_split(\", \", simplify = TRUE) |&gt;\n  as_tibble() |&gt;\n  pivot_longer(cols = (1:144), names_to = NULL, values_to = \"col\") |&gt;\n  separate_wider_delim(\"col\", delim = \"=\", names = c(\"code\", \"country\")) |&gt;\n  mutate(\n  code = as.integer(str_trim(code)),\n  country = str_trim(country) |&gt; str_remove(\",$\")\n)\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n# region codes\nregion_codes_list &lt;- dict$`Variable Type & Codes*`[57] |&gt;\n  str_split(\",\", simplify = TRUE) |&gt;\n  as_tibble() |&gt;\n  pivot_longer(cols = everything(), names_to = NULL, values_to = \"col\") |&gt;\n  mutate(col = str_trim(col)) |&gt; # trim white space\n  filter(col != \"\") |&gt; # filter out blanks\n  separate_wider_delim(\"col\", delim = \"=\", names = c(\"Regions_Report\", \"region\")) |&gt;\n  mutate(\n    region_code = as.integer(str_trim(Regions_Report)),\n    region = str_trim(region),\n    Regions_Report = as.integer(Regions_Report)\n  )\n\n# join data\nfull_data &lt;- data |&gt;\n  left_join(country_codes_list, by = \"code\") |&gt;\n  left_join(region_codes_list, by = \"Regions_Report\")\n\n\nsafe_vax_pct &lt;- full_data |&gt;\n  group_by(country) |&gt;\n  summarise(\n    total_agree = sum(Q25 %in% c(1, 2), na.rm = TRUE),\n    total = n(),\n    percent_safe = total_agree / total * 100,\n    .groups = \"drop\"\n  ) |&gt;\n  left_join(full_data |&gt; select(country, Regions_Report) |&gt; distinct(), by = \"country\") |&gt;\n  mutate(region = case_when( # build regions\n    Regions_Report %in% c(10, 11, 12)      ~ \"Asia\",                      \n    Regions_Report %in% c(3, 13)           ~ \"Middle East and North Africa\",  \n    Regions_Report %in% c(1, 2, 4, 5)      ~ \"Sub-Saharan Africa\",        \n    Regions_Report %in% c(6, 7, 8)         ~ \"Americas\",                  \n    Regions_Report %in% c(14, 15, 16, 17)  ~ \"Europe\",                    \n    Regions_Report == 9                   ~ \"Former Soviet Union\"\n  ))\n\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\nsafe_vax_pct |&gt;\n  filter(!is.na(region)) |&gt;\n  group_by(region) |&gt;\n  mutate(\n    country = fct_reorder(country, percent_safe),  \n    region_median = median(percent_safe, na.rm = TRUE)\n  ) |&gt;\n  ungroup() |&gt;\n  ggplot(aes(x = percent_safe, y = country)) +\n  geom_vline(aes(xintercept = region_median), linetype = \"dashed\", color = \"black\") +\n  geom_point(aes(color = region), size = 3) +\n  facet_wrap(~ region, scales = \"free_y\") +\n  scale_color_manual(values = wes_palette(\"Zissou1\", n = 6, type = \"continuous\")) +\n  labs(\n    title = \"% of people who believe vaccines are safe, by country and global region\",\n    subtitle = \"Dark vertical lines represent region medians\",\n    x = \"% who believe vaccines are safe\",\n    y = NULL,\n    caption = \"Source: Wellcome Global Monitor, Gallup World Poll 2018\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 15),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_blank(),\n    legend.position = \"none\",\n    axis.text.y = element_text(size = 5)\n  )"
  },
  {
    "objectID": "posts/third-post/index.html#second-data-visualization-improvement",
    "href": "posts/third-post/index.html#second-data-visualization-improvement",
    "title": "Lab 2",
    "section": "Second Data Visualization Improvement",
    "text": "Second Data Visualization Improvement\nFor this second plot, you must select a plot that uses maps so you can demonstrate your proficiency with the leaflet package!\n\nSelect a data visualization in the report that you think could be improved. Be sure to cite both the page number and figure title. Do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\nI decided to recreate and improve Chart 2.3: Map of perceived knowledge about science by country which is on page 27 of the report. The map shows the perceived knowledge about science of people in different countries. The authors may be trying to convey that peoples confidence in their science knowledge varies across countries. Certain countries may have lower confidence due to a limited access to educational resources, however it is important to note that plots like these can be damaging as viewers might interpret lower metrics as a reflection of a country’s intelligence/worth (when that is simply not true).\n\nList the variables that appear to be displayed in this visualization.\n\n\nCountry\nPercent who answered “a lot” or “some”\nSurveyed status?\n\n\nNow that you’re versed in the grammar of graphics (ggplot), list the aesthetics used and which variables are specified for each.\n\n\nfill for the percents\ngeometry for country\ncolor for survey status\n\n\nWhat type of graph would you call this?\n\nChoropleth map\n\nList all of the problems or things you would improve about this graph.\n\n\nuse different colors for better contrast\nhover over to see percents\ndifferentiate NA’s more clearly\n\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\nworld &lt;- ne_countries(type = \"countries\", scale = \"small\")\n\nscience_pct &lt;- full_data |&gt;\n  mutate(country = if_else(country == \"United States\", \"United States of America\", country)) |&gt;\n  group_by(country) |&gt;\n  summarise(\n    total_strong = sum(Q1 %in% c(1, 2), na.rm = TRUE),\n    total = n(),\n    percent_strong = total_strong / total * 100\n  )\n\nmap_data &lt;- world |&gt;\n  left_join(science_pct, by = c(\"name\" = \"country\"))\n\nqpal &lt;- colorNumeric(\"YlGnBu\", domain = map_data$percent_strong, na.color = \"white\")\n\nleaflet(map_data) |&gt;\n  addTiles() |&gt;\n  addPolygons(stroke = FALSE, smoothFactor = 0.2, fillOpacity = 1,\n    color = ~qpal(percent_strong),\n    label = ~paste0(name, \": \", round(percent_strong, 1), \"%\")) |&gt;\n  addLegend(pal = qpal, values = map_data$percent_strong, title = \"Knowledge Level (%)\", position = \"bottomright\")|&gt;\n  addControl(\n    html = \"Map of perceived knowledge about science by country\",\n    position = \"topright\"\n  ) |&gt;\n  setView(lng = 0, lat = 0, zoom = 2)"
  },
  {
    "objectID": "posts/third-post/index.html#third-data-visualization-improvement",
    "href": "posts/third-post/index.html#third-data-visualization-improvement",
    "title": "Lab 2",
    "section": "Third Data Visualization Improvement",
    "text": "Third Data Visualization Improvement\nFor this third plot, you must use one of the other ggplot2 extension packages mentioned this week (e.g., gganimate, plotly, patchwork, cowplot).\n\nSelect a data visualization in the report that you think could be improved. Be sure to cite both the page number and figure title. Do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\nFor the second visualization, I chose Chart 3.1: Trust in Scientists Index showing levels of trust by region which is on page 53. The chart shows us the levels in which people trust scientists from different regions. The authors may be trying to display where certain regions may trust scientists less in order to identify where resources/policy changes could be needed.\n\nList the variables that appear to be displayed in this visualization.\n\n\nRegion\nTrust level\nPercent for each level within each region\n\n\nNow that you’re versed in the grammar of graphics (ggplot), list the aesthetics used and which variables are specified for each.\n\n\ny = region\nx = percent\nfill = trust level\n\n\nWhat type of graph would you call this?\n\nThis is a stacked bar chart.\n\nList all of the problems or things you would improve about this graph.\n\n\ncolors are not intuitive\nno clear sorting\nfonts are too small\ntoo crowed\ncould use interactive elements\n\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\ntrust_scientists &lt;- full_data |&gt; # calculate percents by countries\n  filter(WGM_Indexr %in% c(1, 2, 3, 99), !is.na(region)) |&gt;\n  mutate(\n    trust_level = case_when( \n      WGM_Indexr == 1 ~ \"Low\",\n      WGM_Indexr == 2 ~ \"Medium\",\n      WGM_Indexr == 3 ~ \"High\",\n      WGM_Indexr == 99 ~ \"Don't know / Refused\"\n    )\n  ) |&gt;\n  group_by(region, trust_level) |&gt;\n  summarise(n = n(), .groups = \"drop\") |&gt;\n  group_by(region) |&gt;\n  mutate(percent = n / sum(n) * 100)\n\ntrust_global &lt;- full_data |&gt; # calculate global percentage\n  mutate(\n    trust_level = case_when(\n      WGM_Indexr == 1 ~ \"Low\",\n      WGM_Indexr == 2 ~ \"Medium\",\n      WGM_Indexr == 3 ~ \"High\",\n      WGM_Indexr == 99 ~ \"Don't know / Refused\"\n    )\n  ) |&gt;\n  group_by(trust_level) |&gt;\n  summarise(\n    total = n(),\n    .groups = \"drop\"\n  ) |&gt;\n  mutate(\n    percent = total / sum(total) * 100,\n    region = \"World\"\n  )\n\ntrust_scientists &lt;- bind_rows(trust_scientists, trust_global) # bind\n\n\ntrust_scientists &lt;- trust_scientists |&gt;\n  mutate( # create factors\n    trust_level = factor(trust_level, levels = c(\"High\", \"Medium\", \"Low\", \"Don't know / Refused\"))\n  )\n\ncustom_colors &lt;- c(\n  \"Don't know / Refused\" = \"#f4a261\",  \n  \"Low\" = \"#c6dbef\",\n  \"Medium\" = \"#6baed6\",\n  \"High\" = \"#4292c6\"\n)\n\np &lt;- ggplot(trust_scientists, aes(x = percent, y = region, fill = trust_level, text = paste0(\n    \"Region: \", region, \"&lt;br&gt;\",\n    \"Trust Level: \", trust_level, \"&lt;br&gt;\",\n    \"Percent: \", round(percent), \"%\"\n  )\n  )) +\n  geom_col(width = 0.7, position = \"stack\") +\n  scale_fill_manual(values = custom_colors) +\n  labs(\n    title = \"Trust in Scientists Index showing levels of trust by region\",\n    x = \"\",\n    y = \"\",\n    fill = \"Trust Level\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_blank(),\n    axis.text.x = element_blank(),\n    axis.text.y = element_text(size = 12)\n  )\n\nggplotly(p, tooltip = \"text\") |&gt;\n  layout(\n    legend = list( # could not figure out how to switch order in legend\n      orientation = \"h\",\n      x = 0.5,\n      y = 1.10,  \n      xanchor = \"center\",\n      font = list(size = 13)\n    ),\n    margin = list(t = 100)  \n  )"
  },
  {
    "objectID": "posts/first-post/index.html",
    "href": "posts/first-post/index.html",
    "title": "Advanced Visualizations",
    "section": "",
    "text": "Create a Quarto file for ALL Lab 2 (no separate files for Parts 1 and 2).\n\nMake sure your final file is carefully formatted, so that each analysis is clear and concise.\nBe sure your knitted .html file shows all your source code, including any function definitions.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(wesanderson)\nlibrary(leaflet)\nlibrary(rnaturalearth)\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout"
  },
  {
    "objectID": "posts/first-post/index.html#dissecting-a-bad-visualization",
    "href": "posts/first-post/index.html#dissecting-a-bad-visualization",
    "title": "Advanced Visualizations",
    "section": "Dissecting a Bad Visualization",
    "text": "Dissecting a Bad Visualization\nBelow is an example of a less-than-ideal visualization from the collection linked above. It comes to us from data provided for the Wellcome Global Monitor 2018 report by the Gallup World Poll:\n\nWhile there are certainly issues with this image, do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\nThe graph is showing us the percent of people who believe vaccines are safe by country and global region. The authors could be trying to convey regional differences in vaccine trust, outliers, and a central theme that higher-income countries (such as the US) do not always have high trust in vaccines.\n\nList the variables that appear to be displayed in this visualization. Hint: Variables refer to columns in the data.\n\nCountry, region, % of trust, median vaccine trust by region.\n\nNow that you’re versed in the grammar of graphics (e.g., ggplot), list the aesthetics used and which variables are mapped to each.\n\n\nx = % who believe in vaccines\ny = country\ncolor = region\n\n\nWhat type of graph would you call this? Meaning, what geom would you use to produce this plot?\n\nBecause each individual observation is a point, I would call this a geom_point() plot.\n\nProvide at least four problems or changes that would improve this graph. Please format your changes as bullet points!\n\n\nDifferent colors, make them more fun!\nUse faceting to remove stacking\nIncrease font size\nRemove legend (according to Will Chase)"
  },
  {
    "objectID": "posts/first-post/index.html#improving-the-bad-visualization",
    "href": "posts/first-post/index.html#improving-the-bad-visualization",
    "title": "Advanced Visualizations",
    "section": "Improving the Bad Visualization",
    "text": "Improving the Bad Visualization\nThe data for the Wellcome Global Monitor 2018 report can be downloaded at the following site: https://wellcome.ac.uk/reports/wellcome-global-monitor/2018\n\nThere are two worksheets in the downloaded dataset file. You may need to read them in separately, but you may also just use one if it suffices.\n\ndict &lt;- readxl::read_excel(\"/Users/josegarcia/Desktop/STAT_541/wgm2018.xlsx\", sheet = \"Data dictionary\")\n\ndata &lt;- readxl::read_excel(\"/Users/josegarcia/Desktop/STAT_541/wgm2018.xlsx\", sheet = \"Full dataset\") |&gt;\n  rename(code = WP5)\n\n\n# country codes\ncountry_codes_list &lt;- dict$`Variable Type & Codes*`[1] |&gt;\n  str_split(\", \", simplify = TRUE) |&gt;\n  as_tibble() |&gt;\n  pivot_longer(cols = (1:144), names_to = NULL, values_to = \"col\") |&gt;\n  separate_wider_delim(\"col\", delim = \"=\", names = c(\"code\", \"country\")) |&gt;\n  mutate(\n  code = as.integer(str_trim(code)),\n  country = str_trim(country) |&gt; str_remove(\",$\")\n)\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n# region codes\nregion_codes_list &lt;- dict$`Variable Type & Codes*`[57] |&gt;\n  str_split(\",\", simplify = TRUE) |&gt;\n  as_tibble() |&gt;\n  pivot_longer(cols = everything(), names_to = NULL, values_to = \"col\") |&gt;\n  mutate(col = str_trim(col)) |&gt; # trim white space\n  filter(col != \"\") |&gt; # filter out blanks\n  separate_wider_delim(\"col\", delim = \"=\", names = c(\"Regions_Report\", \"region\")) |&gt;\n  mutate(\n    region_code = as.integer(str_trim(Regions_Report)),\n    region = str_trim(region),\n    Regions_Report = as.integer(Regions_Report)\n  )\n\n# join data\nfull_data &lt;- data |&gt;\n  left_join(country_codes_list, by = \"code\") |&gt;\n  left_join(region_codes_list, by = \"Regions_Report\")\n\n\nsafe_vax_pct &lt;- full_data |&gt;\n  group_by(country) |&gt;\n  summarise(\n    total_agree = sum(Q25 %in% c(1, 2), na.rm = TRUE),\n    total = n(),\n    percent_safe = total_agree / total * 100,\n    .groups = \"drop\"\n  ) |&gt;\n  left_join(full_data |&gt; select(country, Regions_Report) |&gt; distinct(), by = \"country\") |&gt;\n  mutate(region = case_when( # build regions\n    Regions_Report %in% c(10, 11, 12)      ~ \"Asia\",                      \n    Regions_Report %in% c(3, 13)           ~ \"Middle East and North Africa\",  \n    Regions_Report %in% c(1, 2, 4, 5)      ~ \"Sub-Saharan Africa\",        \n    Regions_Report %in% c(6, 7, 8)         ~ \"Americas\",                  \n    Regions_Report %in% c(14, 15, 16, 17)  ~ \"Europe\",                    \n    Regions_Report == 9                   ~ \"Former Soviet Union\"\n  ))\n\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\nsafe_vax_pct |&gt;\n  filter(!is.na(region)) |&gt;\n  group_by(region) |&gt;\n  mutate(\n    country = fct_reorder(country, percent_safe),  \n    region_median = median(percent_safe, na.rm = TRUE)\n  ) |&gt;\n  ungroup() |&gt;\n  ggplot(aes(x = percent_safe, y = country)) +\n  geom_vline(aes(xintercept = region_median), linetype = \"dashed\", color = \"black\") +\n  geom_point(aes(color = region), size = 3) +\n  facet_wrap(~ region, scales = \"free_y\") +\n  scale_color_manual(values = wes_palette(\"Zissou1\", n = 6, type = \"continuous\")) +\n  labs(\n    title = \"% of people who believe vaccines are safe, by country and global region\",\n    subtitle = \"Dark vertical lines represent region medians\",\n    x = \"% who believe vaccines are safe\",\n    y = NULL,\n    caption = \"Source: Wellcome Global Monitor, Gallup World Poll 2018\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 15),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_blank(),\n    legend.position = \"none\",\n    axis.text.y = element_text(size = 5)\n  )"
  },
  {
    "objectID": "posts/first-post/index.html#second-data-visualization-improvement",
    "href": "posts/first-post/index.html#second-data-visualization-improvement",
    "title": "Advanced Visualizations",
    "section": "Second Data Visualization Improvement",
    "text": "Second Data Visualization Improvement\nFor this second plot, you must select a plot that uses maps so you can demonstrate your proficiency with the leaflet package!\n\nSelect a data visualization in the report that you think could be improved. Be sure to cite both the page number and figure title. Do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\nI decided to recreate and improve Chart 2.3: Map of perceived knowledge about science by country which is on page 27 of the report. The map shows the perceived knowledge about science of people in different countries. The authors may be trying to convey that peoples confidence in their science knowledge varies across countries. Certain countries may have lower confidence due to a limited access to educational resources, however it is important to note that plots like these can be damaging as viewers might interpret lower metrics as a reflection of a country’s intelligence/worth (when that is simply not true).\n\nList the variables that appear to be displayed in this visualization.\n\n\nCountry\nPercent who answered “a lot” or “some”\nSurveyed status?\n\n\nNow that you’re versed in the grammar of graphics (ggplot), list the aesthetics used and which variables are specified for each.\n\n\nfill for the percents\ngeometry for country\ncolor for survey status\n\n\nWhat type of graph would you call this?\n\nChoropleth map\n\nList all of the problems or things you would improve about this graph.\n\n\nuse different colors for better contrast\nhover over to see percents\ndifferentiate NA’s more clearly\n\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\nworld &lt;- ne_countries(type = \"countries\", scale = \"small\")\n\nscience_pct &lt;- full_data |&gt;\n  mutate(country = if_else(country == \"United States\", \"United States of America\", country)) |&gt;\n  group_by(country) |&gt;\n  summarise(\n    total_strong = sum(Q1 %in% c(1, 2), na.rm = TRUE),\n    total = n(),\n    percent_strong = total_strong / total * 100\n  )\n\nmap_data &lt;- world |&gt;\n  left_join(science_pct, by = c(\"name\" = \"country\"))\n\nqpal &lt;- colorNumeric(\"YlGnBu\", domain = map_data$percent_strong, na.color = \"white\")\n\nleaflet(map_data) |&gt;\n  addTiles() |&gt;\n  addPolygons(stroke = FALSE, smoothFactor = 0.2, fillOpacity = 1,\n    color = ~qpal(percent_strong),\n    label = ~paste0(name, \": \", round(percent_strong, 1), \"%\")) |&gt;\n  addLegend(pal = qpal, values = map_data$percent_strong, title = \"Knowledge Level (%)\", position = \"bottomright\")|&gt;\n  addControl(\n    html = \"Map of perceived knowledge about science by country\",\n    position = \"topright\"\n  ) |&gt;\n  setView(lng = 0, lat = 0, zoom = 2)"
  },
  {
    "objectID": "posts/first-post/index.html#third-data-visualization-improvement",
    "href": "posts/first-post/index.html#third-data-visualization-improvement",
    "title": "Advanced Visualizations",
    "section": "Third Data Visualization Improvement",
    "text": "Third Data Visualization Improvement\nFor this third plot, you must use one of the other ggplot2 extension packages mentioned this week (e.g., gganimate, plotly, patchwork, cowplot).\n\nSelect a data visualization in the report that you think could be improved. Be sure to cite both the page number and figure title. Do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\nFor the second visualization, I chose Chart 3.1: Trust in Scientists Index showing levels of trust by region which is on page 53. The chart shows us the levels in which people trust scientists from different regions. The authors may be trying to display where certain regions may trust scientists less in order to identify where resources/policy changes could be needed.\n\nList the variables that appear to be displayed in this visualization.\n\n\nRegion\nTrust level\nPercent for each level within each region\n\n\nNow that you’re versed in the grammar of graphics (ggplot), list the aesthetics used and which variables are specified for each.\n\n\ny = region\nx = percent\nfill = trust level\n\n\nWhat type of graph would you call this?\n\nThis is a stacked bar chart.\n\nList all of the problems or things you would improve about this graph.\n\n\ncolors are not intuitive\nno clear sorting\nfonts are too small\ntoo crowed\ncould use interactive elements\n\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\ntrust_scientists &lt;- full_data |&gt; # calculate percents by countries\n  filter(WGM_Indexr %in% c(1, 2, 3, 99), !is.na(region)) |&gt;\n  mutate(\n    trust_level = case_when( \n      WGM_Indexr == 1 ~ \"Low\",\n      WGM_Indexr == 2 ~ \"Medium\",\n      WGM_Indexr == 3 ~ \"High\",\n      WGM_Indexr == 99 ~ \"Don't know / Refused\"\n    )\n  ) |&gt;\n  group_by(region, trust_level) |&gt;\n  summarise(n = n(), .groups = \"drop\") |&gt;\n  group_by(region) |&gt;\n  mutate(percent = n / sum(n) * 100)\n\ntrust_global &lt;- full_data |&gt; # calculate global percentage\n  mutate(\n    trust_level = case_when(\n      WGM_Indexr == 1 ~ \"Low\",\n      WGM_Indexr == 2 ~ \"Medium\",\n      WGM_Indexr == 3 ~ \"High\",\n      WGM_Indexr == 99 ~ \"Don't know / Refused\"\n    )\n  ) |&gt;\n  group_by(trust_level) |&gt;\n  summarise(\n    total = n(),\n    .groups = \"drop\"\n  ) |&gt;\n  mutate(\n    percent = total / sum(total) * 100,\n    region = \"World\"\n  )\n\ntrust_scientists &lt;- bind_rows(trust_scientists, trust_global) # bind\n\n\ntrust_scientists &lt;- trust_scientists |&gt;\n  mutate( # create factors\n    trust_level = factor(trust_level, levels = c(\"High\", \"Medium\", \"Low\", \"Don't know / Refused\"))\n  )\n\ncustom_colors &lt;- c(\n  \"Don't know / Refused\" = \"#f4a261\",  \n  \"Low\" = \"#c6dbef\",\n  \"Medium\" = \"#6baed6\",\n  \"High\" = \"#4292c6\"\n)\n\np &lt;- ggplot(trust_scientists, aes(x = percent, y = region, fill = trust_level, text = paste0(\n    \"Region: \", region, \"&lt;br&gt;\",\n    \"Trust Level: \", trust_level, \"&lt;br&gt;\",\n    \"Percent: \", round(percent), \"%\"\n  )\n  )) +\n  geom_col(width = 0.7, position = \"stack\") +\n  scale_fill_manual(values = custom_colors) +\n  labs(\n    title = \"Trust in Scientists Index showing levels of trust by region\",\n    x = \"\",\n    y = \"\",\n    fill = \"Trust Level\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_blank(),\n    axis.text.x = element_blank(),\n    axis.text.y = element_text(size = 12)\n  )\n\nggplotly(p, tooltip = \"text\") |&gt;\n  layout(\n    legend = list( # could not figure out how to switch order in legend\n      orientation = \"h\",\n      x = 0.5,\n      y = 1.10,  \n      xanchor = \"center\",\n      font = list(size = 13)\n    ),\n    margin = list(t = 100)  \n  )"
  },
  {
    "objectID": "posts/fourth-post/index.html",
    "href": "posts/fourth-post/index.html",
    "title": "Writing Efficient Functions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rlang)\nThis assignment will challenge your function writing abilities. I’m not going to lie, these functions are difficult but well within your reach. I do, however, want to recognize that not everyone is interested in being a “virtuoso” with their function writing. So, there are two options for this week’s lab:"
  },
  {
    "objectID": "posts/fourth-post/index.html#testing-your-function",
    "href": "posts/fourth-post/index.html#testing-your-function",
    "title": "Writing Efficient Functions",
    "section": "Testing Your Function!",
    "text": "Testing Your Function!\n\n## Testing how your function handles multiple input variables\nremove_outliers(diamonds, \n                price, \n                x, \n                y, \n                z)\n\n# A tibble: 52,689 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55 0.904  1.59  1.54  1.57\n 2  0.21 Premium   E     SI1      59.8    61 0.904  1.64  1.66  1.74\n 3  0.23 Good      E     VS1      56.9    65 0.904  1.50  1.46  1.74\n 4  0.29 Premium   I     VS2      62.4    58 0.902  1.36  1.32  1.29\n 5  0.31 Good      J     SI2      63.3    58 0.902  1.24  1.21  1.12\n 6  0.24 Very Good J     VVS2     62.8    57 0.902  1.60  1.55  1.50\n 7  0.24 Very Good I     VVS1     62.3    57 0.902  1.59  1.54  1.51\n 8  0.26 Very Good H     SI1      61.9    55 0.901  1.48  1.42  1.43\n 9  0.22 Fair      E     VS2      65.1    61 0.901  1.66  1.71  1.49\n10  0.23 Very Good H     VS1      59.4    61 0.901  1.54  1.47  1.63\n# ℹ 52,679 more rows\n\n## Testing how your function handles an input that isn't numeric\nremove_outliers(diamonds, \n                price, \n                color)\n\nError in remove_outliers(diamonds, price, color): The following columns are not numeric: color\n\n## Testing how your function handles a non-default sd_thresh\nremove_outliers(diamonds, \n                price,\n                x, \n                y, \n                z, \n                sd_thresh = 2)\n\n# A tibble: 50,099 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55 0.904  1.59  1.54  1.57\n 2  0.21 Premium   E     SI1      59.8    61 0.904  1.64  1.66  1.74\n 3  0.23 Good      E     VS1      56.9    65 0.904  1.50  1.46  1.74\n 4  0.29 Premium   I     VS2      62.4    58 0.902  1.36  1.32  1.29\n 5  0.31 Good      J     SI2      63.3    58 0.902  1.24  1.21  1.12\n 6  0.24 Very Good J     VVS2     62.8    57 0.902  1.60  1.55  1.50\n 7  0.24 Very Good I     VVS1     62.3    57 0.902  1.59  1.54  1.51\n 8  0.26 Very Good H     SI1      61.9    55 0.901  1.48  1.42  1.43\n 9  0.22 Fair      E     VS2      65.1    61 0.901  1.66  1.71  1.49\n10  0.23 Very Good H     VS1      59.4    61 0.901  1.54  1.47  1.63\n# ℹ 50,089 more rows\n\n\nExercise 2: Write a function that imputes missing values for numeric variables in a dataset. The user should be able to supply the dataset, the variables to impute values for, and a function to use when imputing. Hint 1: You will need to use across() to apply your function, since the user can input multiple variables. Hint 2: The replace_na() function is helpful here!\n\nimpute_missing &lt;- function(df, ..., impute_fun = mean) {\n  col_quos &lt;- enquos(...)\n  col_names &lt;- map_chr(col_quos, as_name)\n\n  non_num &lt;- df |&gt;\n    select(!!!col_quos) |&gt;\n    map_lgl(~ !is.numeric(.x)) |&gt;\n    keep(identity) |&gt;\n    names()\n\n  if (length(non_num) &gt; 0) {\n    stop(\"The following columns are not numeric: \",\n         str_c(non_num, collapse = \", \"))\n  }\n\n  df |&gt;\n    mutate(across(\n      all_of(col_names),\n      ~ replace_na(., {{ impute_fun }}(., na.rm = TRUE))\n    ))\n}"
  },
  {
    "objectID": "posts/fourth-post/index.html#testing-your-function-1",
    "href": "posts/fourth-post/index.html#testing-your-function-1",
    "title": "Writing Efficient Functions",
    "section": "Testing Your Function!",
    "text": "Testing Your Function!\n\n## Testing how your function handles multiple input variables\nimpute_missing(nycflights13::flights, \n               arr_delay, \n               dep_delay) \n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n## Testing how your function handles an input that isn't numeric\nimpute_missing(nycflights13::flights, \n               arr_delay, \n               carrier)\n\nError in impute_missing(nycflights13::flights, arr_delay, carrier): The following columns are not numeric: carrier\n\n## Testing how your function handles a non-default impute_fun\nimpute_missing(nycflights13::flights, \n               arr_delay, \n               dep_delay, \n               impute_fun = median)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "posts/fourth-post/index.html#testing-your-function-2",
    "href": "posts/fourth-post/index.html#testing-your-function-2",
    "title": "Writing Efficient Functions",
    "section": "Testing Your Function!",
    "text": "Testing Your Function!\n\nfit_model(\n  diamonds,\n  mod_formula = price ~ carat + cut,\n  remove_outliers = TRUE,\n  impute_missing = TRUE,\n  price, \n  carat\n)\n\n\nCall:\nlm(formula = mod_formula, data = df)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n    0.04030      0.82748      0.08566     -0.03968      0.02610      0.01703"
  },
  {
    "objectID": "posts/fourth-post/index.html#parameters",
    "href": "posts/fourth-post/index.html#parameters",
    "title": "Writing Efficient Functions",
    "section": "Parameters",
    "text": "Parameters\nFirst, we need to define the set of parameters we want to iterate the fit_model() function over. The tidyr package has a useful function called crossing() that is useful for generating argument combinations. For each argument, we specify all possible values for that argument and crossing() generates all combinations. Note that you can create a list of formula objects in R with c(y ~ x1, y ~ x1 + x2).\n\ndf_arg_combos &lt;- crossing(\n    impute = c(TRUE, FALSE),\n    remove_outliers = c(TRUE, FALSE), \n    mod = c(y ~ x1, \n            y ~ x1 + x2)\n)\ndf_arg_combos\n\nExercise 4: Use crossing() to create the data frame of argument combinations for our analyses.\n\nmodels &lt;- c(price ~ carat,\n              price ~ carat + cut,\n              price ~ carat + cut + clarity,\n              price ~ carat + cut + clarity + color)\n\nparam_combos &lt;- crossing(\n  mod_formula = models,\n  remove_outliers = c(TRUE, FALSE),\n  impute_missing = c(TRUE, FALSE),\n  \n)"
  },
  {
    "objectID": "posts/fourth-post/index.html#iterating-over-the-parameters",
    "href": "posts/fourth-post/index.html#iterating-over-the-parameters",
    "title": "Writing Efficient Functions",
    "section": "Iterating Over the Parameters",
    "text": "Iterating Over the Parameters\nWe’ve arrived at the final step!\nExercise 5: Use pmap() from purrr to apply the fit_model() function to every combination of arguments from `diamonds.\n\napply_model &lt;- param_combos |&gt;\n  mutate(model = pmap(\n    .l = param_combos,\n    .f = function(mod_formula, impute_missing, remove_outliers) {\n      fit_model(\n        df = diamonds,\n        mod_formula = mod_formula,\n        impute_missing = impute_missing,\n        remove_outliers = remove_outliers,\n        carat \n      )\n    }\n  ))\n  \nhead(apply_model)\n\n# A tibble: 6 × 4\n  mod_formula remove_outliers impute_missing model \n  &lt;list&gt;      &lt;lgl&gt;           &lt;lgl&gt;          &lt;list&gt;\n1 &lt;formula&gt;   FALSE           FALSE          &lt;lm&gt;  \n2 &lt;formula&gt;   FALSE           TRUE           &lt;lm&gt;  \n3 &lt;formula&gt;   TRUE            FALSE          &lt;lm&gt;  \n4 &lt;formula&gt;   TRUE            TRUE           &lt;lm&gt;  \n5 &lt;formula&gt;   FALSE           FALSE          &lt;lm&gt;  \n6 &lt;formula&gt;   FALSE           TRUE           &lt;lm&gt;"
  }
]