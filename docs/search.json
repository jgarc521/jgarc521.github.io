[
  {
    "objectID": "posts/first-post/index.html",
    "href": "posts/first-post/index.html",
    "title": "STAT 415 Project",
    "section": "",
    "text": "library(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ ggplot2   3.5.1     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(brms)\n\nLoading required package: Rcpp\nLoading 'brms' package (version 2.21.0). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n\nAttaching package: 'brms'\n\nThe following object is masked from 'package:stats':\n\n    ar\n\nlibrary(tidybayes)\n\n\nAttaching package: 'tidybayes'\n\nThe following objects are masked from 'package:brms':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nbayes_col = c(\"#56B4E9\", \"#E69F00\", \"#009E73\", \"#CC79A7\", \"#CC79A7\")\nnames(bayes_col) = c(\"prior\", \"likelihood\", \"posterior\", \"prior_predict\", \"posterior_predict\")\n\nbayes_lty = c(\"dashed\", \"dotted\", \"solid\")\nnames(bayes_lty) = c(\"prior\", \"likelihood\", \"posterior\")"
  },
  {
    "objectID": "posts/first-post/index.html#research-question-and-context",
    "href": "posts/first-post/index.html#research-question-and-context",
    "title": "STAT 415 Project",
    "section": "Research Question and Context",
    "text": "Research Question and Context\nOur research question is how does flight departure delay affect customer satisfaction with a flight? The departure delay time will be measured in minutes and we will determine if it influences whether a customer is satisfied or not satisfied with a flight."
  },
  {
    "objectID": "posts/first-post/index.html#data",
    "href": "posts/first-post/index.html#data",
    "title": "STAT 415 Project",
    "section": "Data",
    "text": "Data\n\nairline <- read.csv(\"/Users/josegarcia/Downloads/airline_data.csv\")\nairline <- airline %>%\n  select(Departure.Delay.in.Minutes, satisfaction) %>%\n  rename(dep_delay = Departure.Delay.in.Minutes)\nairline <- airline[1:1000,]\nairline$satisfaction <- ifelse(airline$satisfaction == \"satisfied\", 1, 0)\n\nWe collected data from Kaggle which is a data science platform and online community for data scientists and machine learning practitioners under Google LLC. https://www.kaggle.com/datasets/raminhuseyn/airline-customer-satisfaction\nThe dataset provides a look into customer satisfaction, either satisfied or not satisfied. The data was collected from an undisclosed airline company. There are 129,880 samples within the dataset, but we will be exploring the first 1,000 samples in the dataset. If the dataset is too big it will have too much influence on the posterior distribution, and our prior will not have any influence."
  },
  {
    "objectID": "posts/first-post/index.html#proposed-bayesian-model",
    "href": "posts/first-post/index.html#proposed-bayesian-model",
    "title": "STAT 415 Project",
    "section": "Proposed Bayesian Model",
    "text": "Proposed Bayesian Model\nBased on the data, we propose a Bayesian analog of a logistic regression which is modeled as:\nlog(\\(\\pi\\) / 1 - \\(\\pi\\)i) = \\(\\beta_0\\) + \\(\\beta_1x_j\\) ."
  },
  {
    "objectID": "posts/first-post/index.html#prior-distribution-of-the-parameters",
    "href": "posts/first-post/index.html#prior-distribution-of-the-parameters",
    "title": "STAT 415 Project",
    "section": "Prior Distribution of the Parameters",
    "text": "Prior Distribution of the Parameters\nFor our parameters, we chose the following priors:\n\n\\(\\beta_0\\) (Intercept) ~ N(0, 10)\n\nPrior to seeing the data, we believe the baseline log-odds of satisfaction (when departure delay is zero) could reasonably vary but are centered around zero, reflecting no strong initial bias toward satisfaction or dissatisfaction.\n\n\\(\\beta_1\\) (Coefficient for Departure Delay) ~ N(0, 2)\n\nWe expect that each minute of delay could slightly increase or decrease the probability of satisfaction, but probably not dramatically on a minute-by-minute basis. Therefore, a normal distribution with a smaller standard deviation could make sense, reflecting our belief that substantial changes in odds are unlikely with small changes in delay.\n\n\n\nn_rep = 1000\nx = runif(n_rep, 0, 1600)  \n\n# Simulate parameters from the prior distribution\nbeta0 <- rnorm(n_rep, 0, 10)  \nbeta1 <- rnorm(n_rep, 0, 2)      \n\n# Simulate values of satisfaction \np = exp(beta0 + beta1 * x) / (1 + exp(beta0 + beta1 * x))\ny_pred = rbinom(n_rep, 1, p)\n\nWarning in rbinom(n_rep, 1, p): NAs produced\n\n# Create a dataframe \nsim_data <- data.frame(dep_delay = x, y_pred = y_pred)\n\n# Plot \nggplot(sim_data, aes(x = dep_delay, y = y_pred)) + \n  geom_jitter(width = 0.1, height = 0.05, alpha = 0.5) +\n  labs(x = \"Departure Delay (minutes)\", y = \"Predicted Satisfaction\",\n       title = \"Prior Predictive Distribution of Satisfaction\")\n\nWarning: Removed 295 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nAfter some prior predictive tuning, the resulting plot showcases a lower predicted satisfaction for higher values of departure delay, as seen in the greater density of points at 0 (not satisfied)."
  },
  {
    "objectID": "posts/first-post/index.html#brms-model",
    "href": "posts/first-post/index.html#brms-model",
    "title": "STAT 415 Project",
    "section": "BRMS Model",
    "text": "BRMS Model\n\nfit <- brm(data = airline,\n           satisfaction ~ dep_delay,\n           family = bernoulli(),\n           refresh = 0)\n\nCompiling Stan program...\n\n\nStart sampling"
  },
  {
    "objectID": "posts/first-post/index.html#posterior-inference",
    "href": "posts/first-post/index.html#posterior-inference",
    "title": "STAT 415 Project",
    "section": "Posterior Inference",
    "text": "Posterior Inference\n\nprior_summary(fit)\n\n                prior     class      coef group resp dpar nlpar lb ub\n               (flat)         b                                      \n               (flat)         b dep_delay                            \n student_t(3, 0, 2.5) Intercept                                      \n       source\n      default\n (vectorized)\n      default\n\nsummary(fit)\n\n Family: bernoulli \n  Links: mu = logit \nFormula: satisfaction ~ dep_delay \n   Data: airline (Number of observations: 1000) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     2.26      0.11     2.05     2.47 1.00     1559     2120\ndep_delay    -0.01      0.00    -0.02    -0.01 1.00     3849     2945\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nplot(fit)\n\n\n\npairs(fit)\n\n\n\n\n\nci <- posterior_summary(fit, probs = c(0.025, 0.975))\nprint(ci)\n\n                 Estimate   Est.Error          Q2.5         Q97.5\nb_Intercept    2.25997430 0.106894793    2.04862559  2.473527e+00\nb_dep_delay   -0.01045203 0.002355074   -0.01501899 -5.908706e-03\nIntercept      2.16695122 0.102252579    1.96801279  2.370360e+00\nlprior        -2.36469906 0.037773476   -2.44138358 -2.292733e+00\nlp__        -332.32452595 0.944575105 -334.85667046 -3.314094e+02"
  },
  {
    "objectID": "posts/first-post/index.html#posterior-predictive-distribution",
    "href": "posts/first-post/index.html#posterior-predictive-distribution",
    "title": "STAT 415 Project",
    "section": "Posterior Predictive Distribution",
    "text": "Posterior Predictive Distribution\n\ny_predict = posterior_predict(fit)\ny_predict = data.frame(y_sim = y_predict[, 1])\n\n# Create the labels\ny_predict$y_sim <- factor(y_predict$y_sim, levels = c(0, 1), labels = c(\"Not Satisfied (0)\", \"Satisfied (1)\"))\n\n# Create summary for percentages\nsummary <- y_predict |>\n  group_by(y_sim) |>\n  summarise(Count = n()) |>\n  mutate(Percentage = paste0(round(100 * Count / sum(Count), 1), \"%\"))\n\n# Bar plot\nggplot(summary, aes(x = y_sim, y = Count, fill = y_sim)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = Percentage), vjust = -0.3, size = 5) +\n  labs(title = \"Posterior Predictions for a Single X\",\n       x = \"Prediction of Satisfaction\", \n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\nThe bar plot showing the posterior predictions from a logistic regression model indicates a strong skew towards predicting satisfaction, with about 91.7% of outcomes favoring satisfaction and only 8.3% not. This distribution suggests possible overconfidence or overfitting, where the model might be too finely tuned to the data, potentially failing to capture less frequent outcomes of dissatisfaction accurately."
  },
  {
    "objectID": "posts/first-post/index.html#sensitivity-analysis",
    "href": "posts/first-post/index.html#sensitivity-analysis",
    "title": "STAT 415 Project",
    "section": "Sensitivity Analysis",
    "text": "Sensitivity Analysis\n\nfit_prior <- brm(data = airline,\n           satisfaction ~ dep_delay,\n           family = bernoulli(),\n           prior = c(prior(normal(0, 10), class = Intercept),\n                prior(normal(0, 2), class = b)),\n           refresh = 0)\n\nCompiling Stan program...\n\n\nStart sampling\n\n\n\nsummary(fit_prior)\n\n Family: bernoulli \n  Links: mu = logit \nFormula: satisfaction ~ dep_delay \n   Data: airline (Number of observations: 1000) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     2.27      0.11     2.05     2.50 1.00     1218     1698\ndep_delay    -0.01      0.00    -0.02    -0.01 1.00     3756     2733\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nplot(fit_prior)\n\n\n\npairs(fit_prior)\n\n\n\npairs(fit_prior)\n\n\n\n\n\nci <- posterior_summary(fit_prior, probs = c(0.025, 0.975))\nprint(ci)\n\n                 Estimate   Est.Error          Q2.5         Q97.5\nb_Intercept    2.27151778 0.113490208    2.05463989  2.501131e+00\nb_dep_delay   -0.01043651 0.002515581   -0.01557144 -5.667569e-03\nIntercept      2.17863287 0.108450031    1.97143907  2.397745e+00\nlprior        -4.85741474 0.002370920   -4.86236652 -4.853060e+00\nlp__        -334.93306647 1.047621997 -337.74442437 -3.339055e+02\n\n\nAfter setting our own priors for our model, we got results that we the same. The $\\beta_0$ value was the exact same of 2.27. The $\\beta_1$ values or the slope, were the exact same at -0.01. The 95% credible interval for the intercept is approximately [2.06, 2.48], indicating that we are 95% confident that the true intercept lies within this range. This was pretty much the same as the 95% confidence interval for brm’s priors that was [2.06, 2.49]. The 95% credible interval for `dep_delay` is approximately [-0.016, -0.006], there is a 95% probability that the true value from dep_delay is within the interval. This is sightly different from the 95% credible interval for brm’s priors that was [-0.010, 0.003]. This is probably because brm chose a flat prior for the slope, but we picked one that included some prior knowledge on the slope. Overall, the prior had very little influence on the posterior distribution. So the model is not very sensitivity to the prior."
  },
  {
    "objectID": "posts/first-post/index.html#frequentist-analysis",
    "href": "posts/first-post/index.html#frequentist-analysis",
    "title": "STAT 415 Project",
    "section": "Frequentist Analysis",
    "text": "Frequentist Analysis\n\n# Fit the logistic regression model\nfit_glm <- glm(satisfaction ~ dep_delay, family = binomial(link = \"logit\"), data = airline)\n\n# Summarize the model\nsummary(fit_glm)\n\n\nCall:\nglm(formula = satisfaction ~ dep_delay, family = binomial(link = \"logit\"), \n    data = airline)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  2.26440    0.11071  20.454  < 2e-16 ***\ndep_delay   -0.01031    0.00243  -4.243 2.21e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 676.14  on 999  degrees of freedom\nResidual deviance: 658.03  on 998  degrees of freedom\nAIC: 662.03\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n# Calculate confidence intervals\nconfint(fit_glm)\n\nWaiting for profiling to be done...\n\n\n                  2.5 %       97.5 %\n(Intercept)  2.05331858  2.487825431\ndep_delay   -0.01523186 -0.005648149\n\n# Predict the probabilities of customer satisfication\npredicted_probs <- predict(fit_glm, type = \"response\")\n\nAfter doing a frequentist analysis of our logistical regression model, we got similar results. The \\(\\beta_0\\) values were very similar, it was 2.27 for the Bayes Analysis and 2.26 for the frequentist analysis. The \\(\\beta_1\\) values or the slope, were the exact same at -0.01. The confidence interval for the intercept is [2.053, 2.488]. This means we are 95% of the sample intervals will capture the true intercept. The confidence interval for `dep_delay` is [-0.0152, -0.005], suggesting a negative association with the probability of a customer association. They produce similar intervals that are interpreted differently."
  },
  {
    "objectID": "posts/first-post/index.html#conclusions",
    "href": "posts/first-post/index.html#conclusions",
    "title": "STAT 415 Project",
    "section": "Conclusions",
    "text": "Conclusions\nLooking at the posterior estimates for \\(\\beta_0\\) and \\(\\beta_1\\), the estimate for \\(\\beta_0\\) is 2.27 and \\(\\beta_1\\) is -0.01. The 95% credible interval for the intercept is approximately [2.06, 2.49], indicating that we are 95% confident that the true intercept lies within this range. The 95% credible interval for $\\beta_1$ is approximately [-0.010, 0.003], there is a 95% probability that the true value from dep_delay is within the interval. This means that there is a slight negative association with the departure delay and the probability of a customer being satisfied. \\(\\beta_1\\) is the log-odds of a passenger being satisfied or not with each additional minute of delay. Our research question was how does flight departure delay affect customer satisfaction with a flight? We found that the negative association tells us that as departure delay increases, the log-odds of a passenger being satisfied is going to decrease."
  },
  {
    "objectID": "posts/second-post/index.html",
    "href": "posts/second-post/index.html",
    "title": "Naive Bayes Classification",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(brms)\n\nLoading required package: Rcpp\nLoading 'brms' package (version 2.21.0). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n\nAttaching package: 'brms'\n\nThe following object is masked from 'package:stats':\n\n    ar\n\nlibrary(tidybayes)\n\n\nAttaching package: 'tidybayes'\n\nThe following objects are masked from 'package:brms':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nbayes_col = c(\"#56B4E9\", \"#E69F00\", \"#009E73\", \"#CC79A7\", \"#CC79A7\")\nnames(bayes_col) = c(\"prior\", \"likelihood\", \"posterior\", \"prior_predict\", \"posterior_predict\")\n\nbayes_lty = c(\"dashed\", \"dotted\", \"solid\")\nnames(bayes_lty) = c(\"prior\", \"likelihood\", \"posterior\")\n\n\nTasks\nIn this file, will use naive Bayes classification to classify a person’s opinion on climate change into one of the following categories, based on characteristics including political party, age (years), and income ($ thousands):\n\nClimate change is not real at all\nClimate change is real but not caused by people\nClimate change is real and caused by people\n\nSuppose that it is known that\n\n15% of people believe that climate change is not real at all\n30% of people believe that climate change is real but not caused by people\n55% of people believe that climate change is real and caused by people\nAmong people who believe that climate change is not real, 50% are Republican, ages have mean 53.4 and SD 15.6, and incomes have mean 69.4 and SD 38.0\nAmong people who believe that climate change is real but not caused by people, 40% are Republican, ages have mean 51.5 and SD 16.4, and incomes have mean 83.9 and SD 38.9\nAmong people who believe that climate change is real and caused by people, 13% are Republican, ages have mean 47.7 and SD 16.9, and incomes have mean 88.2 and SD 43.1\n\n\nSuppose a randomly selected person is a Republican. Create a Bayes table and find the posterior probabilities of the person’s opinion on climate change. Which category would you classify this person as?\n\nclass <- c(\"Not Real\", \"Real but not caused\", \"Real and caused\")\n\nprior = c(0.15, 0.30, 0.55)\n\n# likelihood of Republican (evidence) given each belief (class)\nlikelihood = c(0.50, 0.40, 0.13) \n\nproduct = prior * likelihood\n\nposterior = product / sum(product)\n\nposterior_given_repub = posterior\n\nbayes_table = data.frame(class,\n                         prior,\n                         likelihood,\n                         product,\n                         posterior)\n\nbayes_table |>\n  adorn_totals(\"row\") |>\n  kbl(digits = 4) |>\n  kable_styling()\n\n\n\n \n  \n    class \n    prior \n    likelihood \n    product \n    posterior \n  \n \n\n  \n    Not Real \n    0.15 \n    0.50 \n    0.0750 \n    0.2814 \n  \n  \n    Real but not caused \n    0.30 \n    0.40 \n    0.1200 \n    0.4503 \n  \n  \n    Real and caused \n    0.55 \n    0.13 \n    0.0715 \n    0.2683 \n  \n  \n    Total \n    1.00 \n    1.03 \n    0.2665 \n    1.0000 \n  \n\n\n\n\n\n\nBased on the Bayes table, I would classify this person as a believer of “Climate change is real but not caused by people”.\n\nSuppose a randomly selected person is age 75. Create a Bayes table and find the posterior probabilities of the person’s opinion on climate change. Which category would you classify this person as?\n\nclass <- c(\"Not Real\", \"Real but not caused\", \"Real and caused\")\n\nprior = c(0.15, 0.30, 0.55)\n\n# likelihood of being 75 (evidence) given each belief (class)\nlikelihood = c(dnorm(75, 53.4, 15.6),\n               dnorm(75, 51.5, 16.4),\n               dnorm(75, 47.7, 16.9)) \n\nproduct = prior * likelihood\n\nposterior = product / sum(product)\n\nbayes_table = data.frame(class,\n                         prior,\n                         likelihood,\n                         product,\n                         posterior)\n\nbayes_table |>\n  adorn_totals(\"row\") |>\n  kbl(digits = 4) |>\n  kable_styling()\n\n\n\n \n  \n    class \n    prior \n    likelihood \n    product \n    posterior \n  \n \n\n  \n    Not Real \n    0.15 \n    0.0098 \n    0.0015 \n    0.1934 \n  \n  \n    Real but not caused \n    0.30 \n    0.0087 \n    0.0026 \n    0.3437 \n  \n  \n    Real and caused \n    0.55 \n    0.0064 \n    0.0035 \n    0.4630 \n  \n  \n    Total \n    1.00 \n    0.0249 \n    0.0076 \n    1.0000 \n  \n\n\n\n\n\n\nBased on the Bayes table, I would classify this person as a believer of “Climate change is real and caused by people”.\n\nSuppose a randomly selected person has income 40. Create a Bayes table and find the posterior probabilities of the person’s opinion on climate change. Which category would you classify this person as?\n\nclass <- c(\"Not Real\", \"Real but not caused\", \"Real and caused\")\n\nprior = c(0.15, 0.30, 0.55)\n\n# likelihood of income 40 (evidence) given each belief (class)\nlikelihood = c(dnorm(40, 69.4, 38),\n               dnorm(40, 83.9, 38.9),\n               dnorm(40, 88.2, 43.1)) \n\nproduct = prior * likelihood\n\nposterior = product / sum(product)\n\nbayes_table = data.frame(class,\n                         prior,\n                         likelihood,\n                         product,\n                         posterior)\n\nbayes_table |>\n  adorn_totals(\"row\") |>\n  kbl(digits = 4) |>\n  kable_styling()\n\n\n\n \n  \n    class \n    prior \n    likelihood \n    product \n    posterior \n  \n \n\n  \n    Not Real \n    0.15 \n    0.0078 \n    0.0012 \n    0.2115 \n  \n  \n    Real but not caused \n    0.30 \n    0.0054 \n    0.0016 \n    0.2949 \n  \n  \n    Real and caused \n    0.55 \n    0.0050 \n    0.0027 \n    0.4936 \n  \n  \n    Total \n    1.00 \n    0.0182 \n    0.0055 \n    1.0000 \n  \n\n\n\n\n\n\nBased on the Bayes table, I would classify this person as a believer of “Climate change is real and caused by people”.\n\nWhich of the three pieces of information above — Republican party, age 75, income 40 — results in the largest change from prior to posterior? Why?\n\nPolitical affiliation, particularly being a Republican, results in the largest change from prior to posterior. Based on the data, high percentages of Republicans either deny climate change outright or reject human involvement, resulting in a significant weight assigned political affiliation. It is important to note that political ideology includes cultural, social, and economic perspectives that are deeply ingrained.\n\nSuppose a randomly selected person is Republican, is age 75, and has income 40. Create a Bayes table and find the posterior probabilities of the person’s opinion on climate change. Which category would you classify this person as?\n\nclass <- c(\"Not Real\", \"Real but not caused\", \"Real and caused\")\n\nprior = posterior_given_repub\n\n# likelihood of being 75 (evidence) given each belief (class)\nlikelihood_age = c(dnorm(75, 53.4, 15.6),\n               dnorm(75, 51.5, 16.4),\n               dnorm(75, 47.7, 16.9)) \n\n# likelihood of income 40 (evidence) given each belief (class)\nlikelihood_income = c(dnorm(40, 69.4, 38),\n               dnorm(40, 83.9, 38.9),\n               dnorm(40, 88.2, 43.1)) \n\nlikelihood = likelihood_age * likelihood_income\n\nproduct = prior * likelihood\n\nposterior = product / sum(product)\n\nbayes_table = data.frame(class,\n                         prior,\n                         likelihood_age,\n                         likelihood_income,\n                         likelihood,\n                         product,\n                         posterior)\n\nbayes_table |>\n  adorn_totals(\"row\") |>\n  kbl(digits = 4) |>\n  kable_styling()\n\n\n\n \n  \n    class \n    prior \n    likelihood_age \n    likelihood_income \n    likelihood \n    product \n    posterior \n  \n \n\n  \n    Not Real \n    0.2814 \n    0.0098 \n    0.0078 \n    1e-04 \n    0e+00 \n    0.4189 \n  \n  \n    Real but not caused \n    0.4503 \n    0.0087 \n    0.0054 \n    0e+00 \n    0e+00 \n    0.4152 \n  \n  \n    Real and caused \n    0.2683 \n    0.0064 \n    0.0050 \n    0e+00 \n    0e+00 \n    0.1659 \n  \n  \n    Total \n    1.0000 \n    0.0249 \n    0.0182 \n    2e-04 \n    1e-04 \n    1.0000 \n  \n\n\n\n\n\n\nBased on the Bayes table, I would classify this person as a believer of “Climate change is not real at all”.\n\nWhich assumptions of the naive Bayes classification algorithm do you think are the most questionable in the context of the example? Explain your reasoning.\n\nThe most questionable assumptions of the Naive Bayes classifier in predicting opinions on climate change based on political party, age, and income are the conditional independence of predictors and the normality of numerical predictors. These assumptions might not be accurate because the variables are often related in complicated ways, and the numerical data doesn’t always follow a normal distribution."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Naive Bayes Classification\n\n\n\n\n\n\n\n\n\n\n\n\nJose Garcia\n\n\n\n\n\n\n  \n\n\n\n\nSTAT 415 Project\n\n\n\n\n\n\n\nBayesian\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2024\n\n\nJose Garcia\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jose Garcia",
    "section": "",
    "text": "Welcome to my site! Let’s see if this works!\nClick the links below to learn more about me, or, check out some of my projects above."
  }
]