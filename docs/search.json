[
  {
    "objectID": "posts/first-post/index.html",
    "href": "posts/first-post/index.html",
    "title": "STAT 415 Project",
    "section": "",
    "text": "library(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ ggplot2   3.5.1     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(brms)\n\nLoading required package: Rcpp\nLoading 'brms' package (version 2.21.0). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n\nAttaching package: 'brms'\n\nThe following object is masked from 'package:stats':\n\n    ar\n\nlibrary(tidybayes)\n\n\nAttaching package: 'tidybayes'\n\nThe following objects are masked from 'package:brms':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nbayes_col = c(\"#56B4E9\", \"#E69F00\", \"#009E73\", \"#CC79A7\", \"#CC79A7\")\nnames(bayes_col) = c(\"prior\", \"likelihood\", \"posterior\", \"prior_predict\", \"posterior_predict\")\n\nbayes_lty = c(\"dashed\", \"dotted\", \"solid\")\nnames(bayes_lty) = c(\"prior\", \"likelihood\", \"posterior\")"
  },
  {
    "objectID": "posts/first-post/index.html#research-question-and-context",
    "href": "posts/first-post/index.html#research-question-and-context",
    "title": "STAT 415 Project",
    "section": "Research Question and Context",
    "text": "Research Question and Context\nOur research question is how does flight departure delay affect customer satisfaction with a flight? The departure delay time will be measured in minutes and we will determine if it influences whether a customer is satisfied or not satisfied with a flight."
  },
  {
    "objectID": "posts/first-post/index.html#data",
    "href": "posts/first-post/index.html#data",
    "title": "STAT 415 Project",
    "section": "Data",
    "text": "Data\n\nairline <- read.csv(\"/Users/josegarcia/Downloads/airline_data.csv\")\nairline <- airline %>%\n  select(Departure.Delay.in.Minutes, satisfaction) %>%\n  rename(dep_delay = Departure.Delay.in.Minutes)\nairline <- airline[1:1000,]\nairline$satisfaction <- ifelse(airline$satisfaction == \"satisfied\", 1, 0)\n\nWe collected data from Kaggle which is a data science platform and online community for data scientists and machine learning practitioners under Google LLC. https://www.kaggle.com/datasets/raminhuseyn/airline-customer-satisfaction\nThe dataset provides a look into customer satisfaction, either satisfied or not satisfied. The data was collected from an undisclosed airline company. There are 129,880 samples within the dataset, but we will be exploring the first 1,000 samples in the dataset. If the dataset is too big it will have too much influence on the posterior distribution, and our prior will not have any influence."
  },
  {
    "objectID": "posts/first-post/index.html#proposed-bayesian-model",
    "href": "posts/first-post/index.html#proposed-bayesian-model",
    "title": "STAT 415 Project",
    "section": "Proposed Bayesian Model",
    "text": "Proposed Bayesian Model\nBased on the data, we propose a Bayesian analog of a logistic regression which is modeled as:\nlog(\\(\\pi\\) / 1 - \\(\\pi\\)i) = \\(\\beta_0\\) + \\(\\beta_1x_j\\) ."
  },
  {
    "objectID": "posts/first-post/index.html#prior-distribution-of-the-parameters",
    "href": "posts/first-post/index.html#prior-distribution-of-the-parameters",
    "title": "STAT 415 Project",
    "section": "Prior Distribution of the Parameters",
    "text": "Prior Distribution of the Parameters\nFor our parameters, we chose the following priors:\n\n\\(\\beta_0\\) (Intercept) ~ N(0, 10)\n\nPrior to seeing the data, we believe the baseline log-odds of satisfaction (when departure delay is zero) could reasonably vary but are centered around zero, reflecting no strong initial bias toward satisfaction or dissatisfaction.\n\n\\(\\beta_1\\) (Coefficient for Departure Delay) ~ N(0, 2)\n\nWe expect that each minute of delay could slightly increase or decrease the probability of satisfaction, but probably not dramatically on a minute-by-minute basis. Therefore, a normal distribution with a smaller standard deviation could make sense, reflecting our belief that substantial changes in odds are unlikely with small changes in delay.\n\n\n\nn_rep = 1000\nx = runif(n_rep, 0, 1600)  \n\n# Simulate parameters from the prior distribution\nbeta0 <- rnorm(n_rep, 0, 10)  \nbeta1 <- rnorm(n_rep, 0, 2)      \n\n# Simulate values of satisfaction \np = exp(beta0 + beta1 * x) / (1 + exp(beta0 + beta1 * x))\ny_pred = rbinom(n_rep, 1, p)\n\nWarning in rbinom(n_rep, 1, p): NAs produced\n\n# Create a dataframe \nsim_data <- data.frame(dep_delay = x, y_pred = y_pred)\n\n# Plot \nggplot(sim_data, aes(x = dep_delay, y = y_pred)) + \n  geom_jitter(width = 0.1, height = 0.05, alpha = 0.5) +\n  labs(x = \"Departure Delay (minutes)\", y = \"Predicted Satisfaction\",\n       title = \"Prior Predictive Distribution of Satisfaction\")\n\nWarning: Removed 277 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nAfter some prior predictive tuning, the resulting plot showcases a lower predicted satisfaction for higher values of departure delay, as seen in the greater density of points at 0 (not satisfied)."
  },
  {
    "objectID": "posts/first-post/index.html#brms-model",
    "href": "posts/first-post/index.html#brms-model",
    "title": "STAT 415 Project",
    "section": "BRMS Model",
    "text": "BRMS Model\n\nfit <- brm(data = airline,\n           satisfaction ~ dep_delay,\n           family = bernoulli(),\n           refresh = 0)\n\nCompiling Stan program...\n\n\nStart sampling"
  },
  {
    "objectID": "posts/first-post/index.html#posterior-inference",
    "href": "posts/first-post/index.html#posterior-inference",
    "title": "STAT 415 Project",
    "section": "Posterior Inference",
    "text": "Posterior Inference\n\nprior_summary(fit)\n\n                prior     class      coef group resp dpar nlpar lb ub\n               (flat)         b                                      \n               (flat)         b dep_delay                            \n student_t(3, 0, 2.5) Intercept                                      \n       source\n      default\n (vectorized)\n      default\n\nsummary(fit)\n\n Family: bernoulli \n  Links: mu = logit \nFormula: satisfaction ~ dep_delay \n   Data: airline (Number of observations: 1000) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     2.27      0.11     2.06     2.49 1.00     1709     2064\ndep_delay    -0.01      0.00    -0.02    -0.01 1.00     4248     2976\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nplot(fit)\n\n\n\npairs(fit)\n\n\n\n\n\nci <- posterior_summary(fit, probs = c(0.025, 0.975))\nprint(ci)\n\n                Estimate   Est.Error         Q2.5         Q97.5\nb_Intercept    2.2671578 0.112019360    2.0580091  2.488056e+00\nb_dep_delay   -0.0103878 0.002459038   -0.0152843 -5.687944e-03\nIntercept      2.1747063 0.107292926    1.9729286  2.388628e+00\nlprior        -2.3676190 0.039765616   -2.4485061 -2.294445e+00\nlp__        -332.4108244 0.998899951 -335.0992176 -3.314048e+02"
  },
  {
    "objectID": "posts/first-post/index.html#posterior-predictive-distribution",
    "href": "posts/first-post/index.html#posterior-predictive-distribution",
    "title": "STAT 415 Project",
    "section": "Posterior Predictive Distribution",
    "text": "Posterior Predictive Distribution\n\ny_predict = posterior_predict(fit)\ny_predict = data.frame(y_sim = y_predict[, 1])\n\n# Create the labels\ny_predict$y_sim <- factor(y_predict$y_sim, levels = c(0, 1), labels = c(\"Not Satisfied (0)\", \"Satisfied (1)\"))\n\n# Create summary for percentages\nsummary <- y_predict |>\n  group_by(y_sim) |>\n  summarise(Count = n()) |>\n  mutate(Percentage = paste0(round(100 * Count / sum(Count), 1), \"%\"))\n\n# Bar plot\nggplot(summary, aes(x = y_sim, y = Count, fill = y_sim)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = Percentage), vjust = -0.3, size = 5) +\n  labs(title = \"Posterior Predictions for a Single X\",\n       x = \"Prediction of Satisfaction\", \n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\nThe bar plot showing the posterior predictions from a logistic regression model indicates a strong skew towards predicting satisfaction, with about 91.7% of outcomes favoring satisfaction and only 8.3% not. This distribution suggests possible overconfidence or overfitting, where the model might be too finely tuned to the data, potentially failing to capture less frequent outcomes of dissatisfaction accurately."
  },
  {
    "objectID": "posts/first-post/index.html#sensitivity-analysis",
    "href": "posts/first-post/index.html#sensitivity-analysis",
    "title": "STAT 415 Project",
    "section": "Sensitivity Analysis",
    "text": "Sensitivity Analysis\n\nfit_prior <- brm(data = airline,\n           satisfaction ~ dep_delay,\n           family = bernoulli(),\n           prior = c(prior(normal(0, 10), class = Intercept),\n                prior(normal(0, 2), class = b)),\n           refresh = 0)\n\nCompiling Stan program...\n\n\nStart sampling\n\n\n\nsummary(fit_prior)\n\n Family: bernoulli \n  Links: mu = logit \nFormula: satisfaction ~ dep_delay \n   Data: airline (Number of observations: 1000) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     2.27      0.11     2.05     2.48 1.00     1804     2142\ndep_delay    -0.01      0.00    -0.02    -0.01 1.00     3526     3057\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nplot(fit_prior)\n\n\n\npairs(fit_prior)\n\n\n\npairs(fit_prior)\n\n\n\n\n\nci <- posterior_summary(fit_prior, probs = c(0.025, 0.975))\nprint(ci)\n\n                 Estimate   Est.Error          Q2.5         Q97.5\nb_Intercept    2.26966753 0.110124874    2.05465186  2.484733e+00\nb_dep_delay   -0.01047166 0.002470717   -0.01533664 -5.667129e-03\nIntercept      2.17646976 0.104443046    1.97311568  2.386459e+00\nlprior        -4.85736344 0.002277660   -4.86210154 -4.853092e+00\nlp__        -334.87311909 1.016656257 -337.60859579 -3.338994e+02\n\n\nAfter setting our own priors for our model, we got results that we the same. The $\\beta_0$ value was the exact same of 2.27. The $\\beta_1$ values or the slope, were the exact same at -0.01. The 95% credible interval for the intercept is approximately [2.06, 2.48], indicating that we are 95% confident that the true intercept lies within this range. This was pretty much the same as the 95% confidence interval for brm’s priors that was [2.06, 2.49]. The 95% credible interval for `dep_delay` is approximately [-0.016, -0.006], there is a 95% probability that the true value from dep_delay is within the interval. This is sightly different from the 95% credible interval for brm’s priors that was [-0.010, 0.003]. This is probably because brm chose a flat prior for the slope, but we picked one that included some prior knowledge on the slope. Overall, the prior had very little influence on the posterior distribution. So the model is not very sensitivity to the prior."
  },
  {
    "objectID": "posts/first-post/index.html#frequentist-analysis",
    "href": "posts/first-post/index.html#frequentist-analysis",
    "title": "STAT 415 Project",
    "section": "Frequentist Analysis",
    "text": "Frequentist Analysis\n\n# Fit the logistic regression model\nfit_glm <- glm(satisfaction ~ dep_delay, family = binomial(link = \"logit\"), data = airline)\n\n# Summarize the model\nsummary(fit_glm)\n\n\nCall:\nglm(formula = satisfaction ~ dep_delay, family = binomial(link = \"logit\"), \n    data = airline)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  2.26440    0.11071  20.454  < 2e-16 ***\ndep_delay   -0.01031    0.00243  -4.243 2.21e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 676.14  on 999  degrees of freedom\nResidual deviance: 658.03  on 998  degrees of freedom\nAIC: 662.03\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n# Calculate confidence intervals\nconfint(fit_glm)\n\nWaiting for profiling to be done...\n\n\n                  2.5 %       97.5 %\n(Intercept)  2.05331858  2.487825431\ndep_delay   -0.01523186 -0.005648149\n\n# Predict the probabilities of customer satisfication\npredicted_probs <- predict(fit_glm, type = \"response\")\n\nAfter doing a frequentist analysis of our logistical regression model, we got similar results. The \\(\\beta_0\\) values were very similar, it was 2.27 for the Bayes Analysis and 2.26 for the frequentist analysis. The \\(\\beta_1\\) values or the slope, were the exact same at -0.01. The confidence interval for the intercept is [2.053, 2.488]. This means we are 95% of the sample intervals will capture the true intercept. The confidence interval for `dep_delay` is [-0.0152, -0.005], suggesting a negative association with the probability of a customer association. They produce similar intervals that are interpreted differently."
  },
  {
    "objectID": "posts/first-post/index.html#conclusions",
    "href": "posts/first-post/index.html#conclusions",
    "title": "STAT 415 Project",
    "section": "Conclusions",
    "text": "Conclusions\nLooking at the posterior estimates for \\(\\beta_0\\) and \\(\\beta_1\\), the estimate for \\(\\beta_0\\) is 2.27 and \\(\\beta_1\\) is -0.01. The 95% credible interval for the intercept is approximately [2.06, 2.49], indicating that we are 95% confident that the true intercept lies within this range. The 95% credible interval for $\\beta_1$ is approximately [-0.010, 0.003], there is a 95% probability that the true value from dep_delay is within the interval. This means that there is a slight negative association with the departure delay and the probability of a customer being satisfied. \\(\\beta_1\\) is the log-odds of a passenger being satisfied or not with each additional minute of delay. Our research question was how does flight departure delay affect customer satisfaction with a flight? We found that the negative association tells us that as departure delay increases, the log-odds of a passenger being satisfied is going to decrease."
  },
  {
    "objectID": "posts/second-post/index.html",
    "href": "posts/second-post/index.html",
    "title": "My second post",
    "section": "",
    "text": "Wow we are in business!\n\n2*3\n\n[1] 6"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "STAT 415 Project\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\nMy second post\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jose Garcia",
    "section": "",
    "text": "Welcome to my site! Let’s see if this works!\nClick the links below to learn more about me, or, check out some of my projects above."
  }
]